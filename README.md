# Proyecto Big Data: Predicci√≥n de Gravedad de Accidentes de Bicicleta

Este proyecto implementa un pipeline de Big Data completo (ETL + Machine Learning) para predecir la gravedad de accidentes de bicicleta en Madrid, integrando datos de accidentes, estaciones de control y meteorolog√≠a hist√≥rica.

El sistema utiliza **Apache Spark**, **PostgreSQL**, **MLflow** y **Optuna**, todo encapsulado en un entorno **Docker**.

---

## üöÄ 1. Instalaci√≥n y Despliegue del Entorno

Siga estos pasos para configurar y ejecutar el proyecto completo en su m√°quina local.

### Paso 1.1: Clonar el Repositorio

Primero, clone este repositorio de GitHub en su m√°quina local.

```bash
git clone https://github.com/J
cd proyectoBigDataJA
```

### Paso 1.2: Requisitos Previos

* **Docker** instalado y corriendo en su m√°quina.
* **Linux** o **WSL**.


### Paso 1.3: Construir y Ejecutar Contenedores

El script `start_local_env.sh` automatiza todo el despliegue del entorno:
1.  Construye la imagen de Docker (`bigdata`) a partir del `Dockerfile`.
2.  Inicia el contenedor de base de datos (`bigdata-db` con PostgreSQL).
3.  Inicia el contenedor principal (`bigdata`) y abre una terminal interactiva (`bash`).

Desde la ra√≠z del proyecto, ejecute:

```bash
bash start.sh
```

> **Nota:** Al finalizar la ejecuci√≥n del script, usted estar√° **dentro** de la terminal del contenedor (`bash-5.0#` o similar). **Todos los pasos siguientes se ejecutan dentro de esta terminal.**

---

## üß™ 2. Ejecuci√≥n de Pruebas Unitarias

Antes de procesar los datos, validamos la l√≥gica de transformaci√≥n y cruce. El proyecto utiliza `pytest` para validar el preprocesamiento (limpieza, pivoteo) y la l√≥gica de uni√≥n (espacial y temporal).

Ejecute el siguiente comando dentro del contenedor:

```bash
pytest
```

**Resultado esperado:** Ver√° una salida verde indicando que los tests en `tests/test_preprocesamiento.py` y `tests/test_cruce.py` han pasado exitosamente.

---

## ‚öôÔ∏è 3. Ejecuci√≥n del Pipeline ETL (Fases 1 y 2)

Este es el programa principal (`etl.py`) que orquesta la carga de datos, la limpieza, el cruce de fuentes y la materializaci√≥n en la base de datos.

Ejecute el script ETL especificando el destino local:

```bash
python etl.py
```

**Lo que sucede internamente:**
1.  **Fase 1:** Carga y unifica m√∫ltiples CSVs de `datos/accidentes/` y `datos/meteo/`.
2.  **Fase 2:** Realiza un *Cruce Espacial* (distancia euclidiana) y un *Cruce Temporal* (`inner join` con clima).
3.  **Materializaci√≥n:** Escribe la tabla final `dataset_final_ml` en la base de datos PostgreSQL `accidentes_db`.

---

## üóÑÔ∏è 4. Estructura de la Base de Datos (Schema)

Una vez ejecutado el ETL, los datos se almacenan en la tabla `dataset_final_ml` en PostgreSQL. A continuaci√≥n se detalla su estructura para facilitar la consulta y validaci√≥n.

### 4.1 Esquema de la Tabla `dataset_final_ml`

La tabla contiene una fila por cada accidente que pudo ser cruzado exitosamente con una estaci√≥n meteorol√≥gica y datos clim√°ticos.

**Columnas Principales:**
* **`num_expediente`** (string): Identificador √∫nico del accidente.
* **`accidente_grave`** (integer): **Variable Objetivo**. `1` (Grave/Fatal), `0` (Leve).
* **`T_83_t=0`** (double): Temperatura actual (¬∫C).
* **`VV_81_t=0`** (double): Velocidad del Viento actual (m/s).
* **`P_89_t=0`** (double): Precipitaci√≥n actual (l/m¬≤).
* **Variables Temporales (Lag):** `T_83_t-1h`, `T_83_t-2h`, etc. (Estado del clima 1 y 2 horas antes).
* **Variables Categ√≥ricas:** `hora`, `tipo_accidente`, `distrito`, `sexo`, `estado_meteorol√≥gico`.

**Esquema T√©cnico (Spark):**
```text
 |-- num_expediente: string (nullable = true)
 |-- accidente_grave: integer (nullable = true)
 |-- T_83_t=0: double (nullable = true)
 |-- VV_81_t=0: double (nullable = true)
 |-- P_89_t=0: double (nullable = true)
 |-- T_83_t-1h: double (nullable = true)
 |-- VV_81_t-1h: double (nullable = true)
 |-- P_89_t-1h: double (nullable = true)
 |-- T_83_t-2h: double (nullable = true)
 |-- VV_81_t-2h: double (nullable = true)
 |-- P_89_t-2h: double (nullable = true)
 |-- hora: string (nullable = true)
 |-- tipo_accidente: string (nullable = true)
 |-- distrito: string (nullable = true)
 |-- sexo: string (nullable = true)
 |-- estado_meteorol√≥gico: string (nullable = true)
 |-- positiva_alcohol: string (nullable = true)
 |-- positiva_droga: string (nullable = true)
 |-- tipo_persona: string (nullable = true)
```

### 4.2 Muestra de Datos (Output Real)

Ejemplo de registros almacenados en la base de datos, mostrando la correcta integraci√≥n y codificaci√≥n de caracteres:

```text
+--------------+---------------+--------+---------+--------+---------+----------+---------+---------+----------+---------+----+--------------------+-------------------+------+--------------------+----------------+--------------+------------+
|num_expediente|accidente_grave|T_83_t=0|VV_81_t=0|P_89_t=0|T_83_t-1h|VV_81_t-1h|P_89_t-1h|T_83_t-2h|VV_81_t-2h|P_89_t-2h|hora|      tipo_accidente|           distrito|  sexo|estado_meteorol√≥gico|positiva_alcohol|positiva_droga|tipo_persona|
+--------------+---------------+--------+---------+--------+---------+----------+---------+---------+----------+---------+----+--------------------+-------------------+------+--------------------+----------------+--------------+------------+
|   2019S002594|              0|    -1.3|      0.0|     0.0|     -0.1|       0.0|      0.0|      1.9|       0.0|      0.0| H22|Choque contra obs...|             LATINA|Hombre|           Despejado|               N|          NULL|   Conductor|
|   2019S006584|              0|    -1.3|      0.0|     0.0|     -0.1|       0.0|      0.0|      1.9|       0.0|      0.0| H22|Colisi√≥n fronto-l...|        CARABANCHEL|Hombre|           Despejado|               N|          NULL|   Conductor|
|   2019S002591|              0|    -1.3|      0.0|     0.0|     -0.1|       0.0|      0.0|      1.9|       0.0|      0.0| H22|Choque contra obs...|        CARABANCHEL|Hombre|           Despejado|               N|          NULL|   Conductor|
|   2020S001062|              0|    11.9|      0.0|     0.0|     10.5|       0.0|      0.0|      9.0|       0.0|      0.0| H16| Atropello a persona|           CHAMBER√ç|Hombre|           Despejado|               N|          NULL|   Conductor|
|   2019S001738|              0|     9.0|      0.0|     0.0|      3.3|       0.0|      0.0|     -0.6|       0.0|      0.0| H13|               Ca√≠da|FUENCARRAL-EL PARDO|Hombre|           Despejado|               N|          NULL|   Conductor|
+--------------+---------------+--------+---------+--------+---------+----------+---------+---------+----------+---------+----+--------------------+-------------------+------+--------------------+----------------+--------------+------------+
```

### 4.3 Verificaci√≥n Manual con SQL

Puede conectarse a la base de datos para ejecutar sus propias consultas de validaci√≥n:

```bash
# Desde la terminal del contenedor:
psql -h 172.17.0.1 -p 5433 -U postgres -d accidentes_db
# Contrase√±a: testPassword
```

**Consultas sugeridas:**
```sql
SELECT count(*) FROM dataset_final_ml;
SELECT accidente_grave, count(*) FROM dataset_final_ml GROUP BY accidente_grave;
SELECT AVG("T_83_t=0") as temp_media FROM dataset_final_ml;
```

---

## üìì 5. Experimentaci√≥n y An√°lisis (Fases 3-5)

Una vez que los datos est√°n en la base de datos, procedemos con el An√°lisis Exploratorio (EDA) y el Dise√±o de Experimentos (DOE).

### Paso 5.1: Iniciar Jupyter

Dentro de la terminal del contenedor, inicie el servidor de Jupyter:

```bash
jupyter notebook --ip 0.0.0.0 --no-browser --allow-root
```

### Paso 5.2: Abrir el Notebook

1.  Copie la URL que aparece en la terminal (algo como `http://127.0.0.1:8888/?token=...`).
2.  √Åbrala en su navegador web.
3.  Navegue a la carpeta `notebooks/` y abra el archivo:
    * **`ProyectoCompleto_BigData.ipynb`**

### Paso 5.3: Ejecutar el Flujo

Ejecute las celdas del notebook en orden. El flujo cubre:
* **Fase 3 (EDA):** Carga de datos desde PostgreSQL y an√°lisis de correlaciones.
* **Fase 4 (DOE):** Ejecuci√≥n de 12 experimentos controlados (Taguchi L12) usando **MLflow** local (en `./mlruns`) para rastrear resultados. Compara estrategias de desbalanceo (`Weights`, `RUS`, `ROS`).
* **Fase 5 (Duelo Final):** Selecci√≥n autom√°tica del mejor "Campe√≥n", re-optimizaci√≥n, y evaluaci√≥n final en el conjunto de test.

---

## üìÇ Estructura del Proyecto

```text
.
‚îú‚îÄ‚îÄ datos/                  # Archivos CSV fuente (Accidentes, Estaciones, Meteo) y Metadatos
‚îú‚îÄ‚îÄ notebooks/              # Jupyter Notebooks para experimentaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ ProyectoCompleto_BigData.ipynb
‚îú‚îÄ‚îÄ src/                    # C√≥digo fuente modular (ETL)
‚îÇ   ‚îú‚îÄ‚îÄ preprocesamiento.py
‚îÇ   ‚îú‚îÄ‚îÄ cruce.py
‚îÇ   ‚îî‚îÄ‚îÄ materializacion.py
‚îú‚îÄ‚îÄ tests/                  # Pruebas unitarias (pytest)
‚îú‚îÄ‚îÄ etl.py                  # Script orquestador principal
‚îú‚îÄ‚îÄ Dockerfile              # Definici√≥n de la imagen
‚îú‚îÄ‚îÄ start.sh      # Script de arranque del entorno
‚îú‚îÄ‚îÄ README.md               # Instrucciones de ejecuci√≥n
‚îî‚îÄ‚îÄ postgresql-42.2.14.jar  # driver PSQL
```